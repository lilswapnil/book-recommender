{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMVekhAQM/cJ5o/c5Y0e0JK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lilswapnil/book-recommender/blob/main/notebook/text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Text Classification"
      ],
      "metadata": {
        "id": "bZ1dNj826HUU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.0 Requirements, Credentials & Libraries"
      ],
      "metadata": {
        "id": "pVt5GxSjEW4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "HF_TOKEN = userdata.get(\"HUGGINGFACEHUB_API_TOKEN\")\n",
        "OPENAI_KEY = userdata.get(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "0pb5hBgW8DaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "5LoR5LMEKWy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path where you saved the file in Google Drive\n",
        "drive_path = '/content/drive/MyDrive/books.csv'\n",
        "\n",
        "# Load the CSV file into a pandas DataFrame\n",
        "loaded_books_df = pd.read_csv(drive_path)\n",
        "\n",
        "# Display the first few rows to verify\n",
        "print(f\"Successfully loaded 'books.csv' from Google Drive. Shape: {loaded_books_df.shape}\")\n",
        "display(loaded_books_df.head())"
      ],
      "metadata": {
        "id": "opKDiAfo8rPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1. Text Classification (Zero Shot Classification on Genre)"
      ],
      "metadata": {
        "id": "sG6SwIquEfz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_books_df['genre'].value_counts().reset_index()"
      ],
      "metadata": {
        "id": "28BXzR8I8w6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_books_df['genre'].value_counts().reset_index().query(\"count >= 50\").sort_values('count', ascending=False)"
      ],
      "metadata": {
        "id": "X0Q0AJD59JmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_books_df.head()"
      ],
      "metadata": {
        "id": "0G6XJxrW_4ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_books_df[\"genre\"] = loaded_books_df[\"genre\"].str.split(\",\")\n",
        "loaded_books_df"
      ],
      "metadata": {
        "id": "RUVhfDIZ_KjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_books_df.info()"
      ],
      "metadata": {
        "id": "nqfoY3QFARK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_books_df[\"genre\"] = loaded_books_df[\"genre\"].apply(\n",
        "    lambda x: list(set([g.strip() for g in x])) if isinstance(x, list) else []\n",
        ")"
      ],
      "metadata": {
        "id": "rnb273V2AJIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genre_counts = (\n",
        "    loaded_books_df.explode(\"genre\")\n",
        "      .groupby(\"genre\")\n",
        "      .size()\n",
        "      .sort_values(ascending=False)\n",
        ")\n",
        "\n",
        "genre_counts.head()"
      ],
      "metadata": {
        "id": "JrNPp6yRAzJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_mapping = {\n",
        "\n",
        "    # --- FICTION ---\n",
        "    \"Fiction\": \"Fiction\",\n",
        "    \"Literary Fiction\": \"Fiction\",\n",
        "    \"Historical Fiction\": \"Fiction\",\n",
        "    \"Romance\": \"Fiction\",\n",
        "    \"Drama\": \"Fiction\",\n",
        "    \"Thrillers\": \"Fiction\",\n",
        "    \"Mystery\": \"Fiction\",\n",
        "    \"Science Fiction\": \"Fiction\",\n",
        "    \"Fantasy\": \"Fiction\",\n",
        "    \"Horror\": \"Fiction\",\n",
        "    \"Comics & Graphic Novels\": \"Fiction\",\n",
        "    \"Poetry\": \"Fiction\",\n",
        "\n",
        "    # --- CHILDREN ---\n",
        "    \"Juvenile Fiction\": \"Children's Fiction\",\n",
        "    \"Children\": \"Children's Fiction\",\n",
        "    \"Young Adult Fiction\": \"Children's Fiction\",\n",
        "\n",
        "    \"Juvenile Nonfiction\": \"Children's Nonfiction\",\n",
        "    \"Young Adult Nonfiction\": \"Children's Nonfiction\",\n",
        "\n",
        "    # --- NONFICTION CORE ---\n",
        "    \"Nonfiction\": \"Nonfiction\",\n",
        "    \"Biography & Autobiography\": \"Nonfiction\",\n",
        "    \"History\": \"Nonfiction\",\n",
        "    \"Philosophy\": \"Nonfiction\",\n",
        "    \"Religion\": \"Nonfiction\",\n",
        "    \"Literary Criticism\": \"Nonfiction\",\n",
        "    \"Science\": \"Nonfiction\",\n",
        "    \"Mathematics\": \"Nonfiction\",\n",
        "    \"Political Science\": \"Nonfiction\",\n",
        "    \"Sociology\": \"Nonfiction\",\n",
        "    \"Psychology\": \"Nonfiction\",\n",
        "\n",
        "    # --- HOBBY / LIFESTYLE ---\n",
        "    \"Art\": \"Lifestyle\",\n",
        "    \"Music\": \"Lifestyle\",\n",
        "    \"Crafts\": \"Lifestyle\",\n",
        "    \"Quilting\": \"Lifestyle\",\n",
        "    \"Origami\": \"Lifestyle\",\n",
        "    \"Games\": \"Lifestyle\",\n",
        "    \"Chess\": \"Lifestyle\",\n",
        "    \"Cooking\": \"Lifestyle\",\n",
        "    \"Wine\": \"Lifestyle\",\n",
        "    \"Alcohol\": \"Lifestyle\",\n",
        "\n",
        "    # --- PROFESSIONAL / TECH ---\n",
        "    \"Business\": \"Professional\",\n",
        "    \"Economics\": \"Professional\",\n",
        "    \"Technology\": \"Professional\",\n",
        "    \"Computers\": \"Professional\",\n",
        "    \"Engineering\": \"Professional\",\n",
        "    \"Medical\": \"Professional\",\n",
        "    \"Nursing\": \"Professional\",\n",
        "    \"Law\": \"Professional\",\n",
        "    \"Education\": \"Professional\",\n",
        "\n",
        "    # --- ESOTERIC ---\n",
        "    \"Occult\": \"Spiritual & Esoteric\",\n",
        "    \"Tarot\": \"Spiritual & Esoteric\",\n",
        "    \"Astrology\": \"Spiritual & Esoteric\",\n",
        "    \"Esoterica\": \"Spiritual & Esoteric\",\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "t4UQmOiHBarS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simplify_to_primary(cat_value):\n",
        "\n",
        "    # Case 1: null\n",
        "    if cat_value is None:\n",
        "        return \"Other\"\n",
        "\n",
        "    # Case 2: already a list\n",
        "    if isinstance(cat_value, list):\n",
        "        categories = cat_value\n",
        "\n",
        "    # Case 3: string\n",
        "    elif isinstance(cat_value, str):\n",
        "        categories = [c.strip() for c in cat_value.split(\",\")]\n",
        "\n",
        "    else:\n",
        "        return \"Other\"\n",
        "\n",
        "    # Map to primary category\n",
        "    for c in categories:\n",
        "        if c in category_mapping:\n",
        "            return category_mapping[c]\n",
        "\n",
        "    return \"Other\"\n",
        "\n",
        "\n",
        "loaded_books_df[\"category\"] = loaded_books_df[\"genre\"].apply(simplify_to_primary)"
      ],
      "metadata": {
        "id": "DTI8a_089mUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_books_df['category'].value_counts().reset_index()"
      ],
      "metadata": {
        "id": "XOWHVhnaBv68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_books_df[~loaded_books_df['genre'].isna()]"
      ],
      "metadata": {
        "id": "n9HGHqT0CJgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_books_df.shape"
      ],
      "metadata": {
        "id": "TwujXXG5C-We"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_books_df.to_csv('categorized_books.csv', index=False)"
      ],
      "metadata": {
        "id": "S3GyHTMU-UQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Transformer Model"
      ],
      "metadata": {
        "id": "r0hCt4irELBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "classifier = pipeline(\n",
        "    \"zero-shot-classification\",\n",
        "    model=\"facebook/bart-large-mnli\",\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "id": "ehlo-xRCET2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fiction_categories = ['Fiction', 'Nonfiction']"
      ],
      "metadata": {
        "id": "TL7wkGk4Fu0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence = loaded_books_df.loc[loaded_books_df[\"category\"] == \"Fiction\", \"desc\"].dropna().iloc[0]\n",
        "print(sequence)\n"
      ],
      "metadata": {
        "id": "1Ak63BHIGo_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(sequence))"
      ],
      "metadata": {
        "id": "zI1osTO8HhAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier(sequence, fiction_categories)"
      ],
      "metadata": {
        "id": "kkmxILDzJuGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = classifier(sequence, fiction_categories)\n",
        "\n",
        "max_index = np.argmax(result[\"scores\"])\n",
        "max_label = result[\"labels\"][max_index]\n",
        "\n",
        "print(f\"The book is {max_label}\")"
      ],
      "metadata": {
        "id": "TCtjGqc9KJk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_predictions(sequence, categories):\n",
        "    result = classifier(sequence, categories)\n",
        "    return result[\"labels\"][int(np.argmax(result[\"scores\"]))]"
      ],
      "metadata": {
        "id": "LER3Ev9TLIhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tqdm import tqdm\n",
        "\n",
        "# actual_cats = []\n",
        "# predicted_cats = []\n",
        "\n",
        "# for i in tqdm(range(0, 300)):\n",
        "#   sequence = loaded_books_df.loc[loaded_books_df['category'] == 'Fiction', 'desc'].reset_index(drop=True)[i]\n",
        "\n",
        "#   predicted_cats.append(generate_predictions(sequence, fiction_categories))\n",
        "#   actual_cats += ['Fiction']"
      ],
      "metadata": {
        "id": "ktNnJ85VLs1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in tqdm(range(0, 300)):\n",
        "#   sequence = loaded_books_df.loc[loaded_books_df['category'] == 'Nonfiction', 'desc'].reset_index(drop=True)[i]\n",
        "#   predicted_cats.append(generate_predictions(sequence, fiction_categories))\n",
        "#   actual_cats += ['Nonfiction']"
      ],
      "metadata": {
        "id": "Pf7VdAADMSOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Build a balanced subset: 300 Fiction + 300 Nonfiction\n",
        "fiction_df = loaded_books_df.loc[loaded_books_df[\"category\"] == \"Fiction\"].head(300)\n",
        "nonfiction_df = loaded_books_df.loc[loaded_books_df[\"category\"] == \"Nonfiction\"].head(300)\n",
        "\n",
        "subset = pd.concat([fiction_df, nonfiction_df], axis=0).reset_index(drop=True)\n",
        "\n",
        "# 2) Create text input (title + desc)\n",
        "texts = (\n",
        "    subset[\"title\"].fillna(\"\").astype(str) + \" \" +\n",
        "    subset[\"desc\"].fillna(\"\").astype(str)\n",
        ").tolist()\n",
        "\n",
        "# 3) Run classifier in batches on GPU\n",
        "results = classifier(texts, fiction_categories, batch_size=16)\n",
        "\n",
        "# 4) Extract predictions + actuals\n",
        "predicted_cats = [r[\"labels\"][0] for r in results]   # top label\n",
        "actual_cats = subset[\"category\"].tolist()\n",
        "\n",
        "print(len(actual_cats), len(predicted_cats))  # should both be 600"
      ],
      "metadata": {
        "id": "sfRfZX_SYs8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_df = pd.DataFrame({\n",
        "    \"actual_categories\": actual_cats,\n",
        "    \"predicted_categories\": predicted_cats\n",
        "})\n",
        "prediction_df[\"correct_prediction\"] = prediction_df[\"actual_categories\"] == prediction_df[\"predicted_categories\"]"
      ],
      "metadata": {
        "id": "MnwZ5UnKMlgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "incorrect_results = prediction_df[prediction_df[\"correct_prediction\"] == False]\n",
        "prediction_df[\"correct_prediction\"].value_counts()"
      ],
      "metadata": {
        "id": "4wHiig88PTOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "print(confusion_matrix(prediction_df[\"actual_categories\"],\n",
        "                       prediction_df[\"predicted_categories\"]))\n",
        "\n",
        "print(classification_report(prediction_df[\"actual_categories\"],\n",
        "                            prediction_df[\"predicted_categories\"]))"
      ],
      "metadata": {
        "id": "IzKdjRnxQD2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results[20]"
      ],
      "metadata": {
        "id": "8HmzseV8JAgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "other_cats = loaded_books_df['category'] == 'Other'\n",
        "other_cats.value_counts()"
      ],
      "metadata": {
        "id": "quR98DwPuv0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "isbns = []\n",
        "predicted_cats = []\n",
        "\n",
        "missing_cats = loaded_books_df.loc[\n",
        "    loaded_books_df[\"category\"] == \"Other\",\n",
        "    [\"isbn\", \"desc\"]\n",
        "].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "e8kbJnMrsIN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for i in tqdm(range(len(missing_cats))):\n",
        "    sequence = missing_cats[\"desc\"].iloc[i]\n",
        "    predicted_cats.append(generate_predictions(sequence, fiction_categories))\n",
        "    isbns.append(missing_cats[\"isbn\"].iloc[i])"
      ],
      "metadata": {
        "id": "It_mRRn2s96O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_prediction_df = pd.DataFrame({\n",
        "    \"isbn\": isbns,\n",
        "    \"predicted_categories\": predicted_cats\n",
        "})\n",
        "missing_prediction_df"
      ],
      "metadata": {
        "id": "XyRDjX6WvlkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find total books with category other\n",
        "loaded_books_df.loc[loaded_books_df['category'] == 'Other']"
      ],
      "metadata": {
        "id": "pcI9P2wk1cRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) remove any old predicted columns from prior merges\n",
        "loaded_books_df = loaded_books_df.drop(\n",
        "    columns=[c for c in loaded_books_df.columns if c.startswith(\"predicted_categories\")],\n",
        "    errors=\"ignore\"\n",
        ")\n",
        "\n",
        "# 2) merge fresh\n",
        "loaded_books_df = pd.merge(loaded_books_df, missing_prediction_df, on=\"isbn\", how=\"left\")\n",
        "\n",
        "# 3) overwrite category only where needed\n",
        "mask = (loaded_books_df[\"category\"] == \"Other\") & loaded_books_df[\"predicted_categories\"].notna()\n",
        "loaded_books_df.loc[mask, \"category\"] = loaded_books_df.loc[mask, \"predicted_categories\"]\n",
        "\n",
        "# 4) final df without helper column\n",
        "books = loaded_books_df.drop(columns=[\"predicted_categories\"])"
      ],
      "metadata": {
        "id": "hYDXZgWDAbtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books"
      ],
      "metadata": {
        "id": "DGD09KQ1Atcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books.to_csv('categorized_books.csv', index = False)"
      ],
      "metadata": {
        "id": "A0cEnhgaCxyD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}